# -*- coding: utf-8 -*-
"""LVADSUSR148_DeepakSridharanM_Lab3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15FQi-rWDwNDgm6RVEGljGxFjmIY1C2CN
"""

import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt

import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

df = pd.read_csv("/content/customer_segmentation.csv")
df.head()

df.columns

df.shape

df.describe(include="all").T

df.info()

df.isnull().sum()
df=df.dropna()

df.isna().sum()

# df.isnull().sum()
# # kNNImputer to fill the missing values
# impute=KNNImputer()
# for i in df.select_dtypes(include='number').columns:
#   df[i]=impute.fit_transform(df[[i]])
# from sklearn.impute import KNNImputer

df.duplicated().sum()

#treating outliers
numerical_columns = df.columns[df.dtypes != "object"]
numerical_columns
for i in numerical_columns:
  plt.figure(figsize = (10,6))
  sns.boxplot(data=df[i])
  plt.title(i)
  plt.ylabel('Values')
  plt.xticks(rotation = 45)
  plt.show()

def detect_and_treat_outliers(df,columns):

  for col in columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    median = df[col].median()
    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), median, df[col])

  return df

df = detect_and_treat_outliers(df,numerical_columns)
numerical_columns = df.columns[df.dtypes != "object"]

# after removing outliers
for i in numerical_columns:
  plt.figure(figsize = (10,6))
  sns.boxplot(data=df[i])
  plt.title(i)
  plt.ylabel('Values')
  plt.xticks(rotation = 45)
  plt.show()

df.duplicated().sum()

df.describe(include='all').T

df = df.drop('ID', axis=1)

df = df.drop('Dt_Customer',  axis=1)

df = df.drop('Year_Birth',  axis=1)

df=df.drop(columns=["AcceptedCmp3","AcceptedCmp4","AcceptedCmp5","AcceptedCmp1","AcceptedCmp2"],axis=1)

df=df.drop(columns=["Complain","Z_CostContact","Z_Revenue","Response"])

df.info()

# #encoding
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df["Education"] = le.fit_transform(df["Education"])
df["Marital_Status"] = le.fit_transform(df["Marital_Status"])

# from sklearn.preprocessing import LabelEncoder

# le = LabelEncoder()

# for col in df.select_dtypes(include='object'):
#   df[col] = le.fit_transform(df[col])

df.head()

cor = df.select_dtypes(include = ['float64','int64']).corr()

cor

plt.figure(figsize=(20,12))
sns.heatmap(cor,annot=True,cmap='Greens')
plt.show()

scaler = MinMaxScaler()
for column in df.select_dtypes(include=['float64','int64']):
  df[column] = scaler.fit_transform(df[[column]])

print(df.head())

sse = [] # The sum of Squared Errors =SSE
k_rng = range(1,10)
for k in k_rng:
   km = KMeans(n_clusters=k)
   km.fit(df[['Income','NumCatalogPurchases']])
   sse.append(km.inertia_)

plt.xlabel('K')
plt.ylabel('Sum of squared error')
plt.plot(k_rng,sse)

km = KMeans(n_clusters=2)
y_predicted = km.fit_predict(df[['Income','NumCatalogPurchases']])
print(y_predicted)
df['cluster']=y_predicted
print(df.head(25))
print(km.cluster_centers_)

df1 = df[df.cluster==0]
df2 = df[df.cluster==1]
df3 = df[df.cluster==2]
plt.scatter(df1.Income,df1['NumCatalogPurchases'],color='green')
plt.scatter(df2.Income,df2['NumCatalogPurchases'],color='red')
# plt.scatter(df3.num_likes,df3['num_loves'],color='black')
plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='purple',marker='*',label='centroid')
plt.xlabel('num_likes')
plt.ylabel('num_loves')
plt.legend()

silhouette_score(df, y_predicted)